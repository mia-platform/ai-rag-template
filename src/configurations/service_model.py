# generated by datamodel-codegen:
#   filename:  service_config.json
#   timestamp: 2024-05-03T10:27:44+00:00

from __future__ import annotations

from enum import Enum
from typing import Optional

from pydantic import BaseModel, Field


class Llm(BaseModel):
    name: str = Field(
        ...,
        description='The name of the language model (llm) to be used by RAG-template for natural language processing and understanding.',
    )
    url: Optional[str] = Field(None, description='The URL of the language model.')
    temperature: Optional[float] = Field(
        0.7,
        description='The temperature parameter for sampling from the language model. A higher value increases the randomness of the generated text.',
    )


class Tokenizer(BaseModel):
    name: Optional[str] = Field(
        'gpt-3.5-turbo', description='The name of the tokenizer'
    )


class Embeddings(BaseModel):
    name: str = Field(
        ...,
        description='The name of the embeddings model to be used by RAG-template for various tasks such as text representation and similarity.',
    )


class RelevanceScoreFn(Enum):
    euclidean = 'euclidean'
    cosine = 'cosine'
    dotProduct = 'dotProduct'


class VectorStore(BaseModel):
    dbName: Optional[str] = Field(
        None, description='The name of the database where the vector store is hosted.'
    )
    collectionName: str = Field(
        ...,
        description='The name of the collection of vectors to be used by RAG-template for various tasks such as text representation and similarity.',
    )
    indexName: str = Field(
        ...,
        description='The name of the index to be used by RAG-template for various tasks such as text representation and similarity.',
    )
    relevanceScoreFn: Optional[RelevanceScoreFn] = Field(
        'euclidean',
        description="The function used to calculate relevance scores for vectors. Options: 'euclidean', 'cosine', 'dotProduct'.",
    )
    embeddingKey: str = Field(
        ..., description='The key used to identify embeddings in the vector store.'
    )
    textKey: str = Field(
        ..., description='The key used to store text data in the vector store.'
    )
    maxDocumentsToRetrieve: Optional[int] = Field(
        4,
        description='The maximum number of documents to be retrieved from the vector store.',
    )
    maxScoreDistance: Optional[float] = Field(
        None, description='The maximum score distance for the vectors.'
    )
    minScoreDistance: Optional[float] = Field(
        None, description='The maximum score distance for the vectors.'
    )


class PromptsFilePath(BaseModel):
    system: Optional[str] = Field(
        None, description='The system prompt to be used for the RAG chain.'
    )
    user: Optional[str] = Field(
        None, description='The user prompt to be used for the RAG chain.'
    )


class Rag(BaseModel):
    promptsFilePath: Optional[PromptsFilePath] = None


class Chain(BaseModel):
    aggregateMaxTokenNumber: Optional[int] = Field(
        2000,
        description='The maximum number of tokens to be used for aggregation of multiple responses from different services.',
    )
    rag: Optional[Rag] = Field(None, description='RAG chain configuration')


class RagTemplateConfigSchema(BaseModel):
    llm: Llm
    tokenizer: Optional[Tokenizer] = Field(
        default_factory=lambda: Tokenizer.parse_obj({'name': 'gpt-3.5-turbo'})
    )
    embeddings: Embeddings
    vectorStore: VectorStore
    chain: Optional[Chain] = Field(
        default_factory=lambda: Chain.parse_obj({'aggregateMaxTokenNumber': 2000})
    )
